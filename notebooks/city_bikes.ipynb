{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CityBikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a request to CityBikes for the city of your choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Python 3.9.20\n",
    "import pandas as pd \n",
    "import requests # this will be used to call the APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choosing Miami as it has a decent number of entries at 167 rows\n",
    "url = \"http://api.citybik.es/v2/networks/citi-bike-miami\"\n",
    "# Make the API request\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse through the response to get the details you want for the bike stations in that city (latitude, longitude, number of bikes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your parsed results into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspection of the json revealed two layers to dig through to get to our information\n",
    "df = pd.DataFrame(data['network']['stations'])\n",
    "extra_list = df['extra'] #create a new dataframe of just the extra column\n",
    "df_extra = extra_list.apply(pd.Series) #turn the extras column into its own seperate table, not sure if we need it but don't want to throw it away yet\n",
    "df.drop('extra', axis=1, inplace = True) # get rid of the extra column from the original dataframe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on further study here we can see that the \"name\" column is a concatenation of \"UID\" and \"address\" from the extra column, so we will drop name and add extra back in as seperate columns\n",
    "df['uid'] = df_extra['uid']\n",
    "df['address'] = df_extra['address']\n",
    "df.drop('name', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after inspection it is revealed \"timestamp\" column is currently a integer so lets convert that to a timestamp\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "#and we are going to rename \"id\" to \"bs_id\"(bike station id) so we dont get confused between stations\n",
    "df.rename(columns = {'id':'bs_id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally lets save this as a pickle file so it will preserve our formatting\n",
    "df.to_pickle('../data/bike_dataframe.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
